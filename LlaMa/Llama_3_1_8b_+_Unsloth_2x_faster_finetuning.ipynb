{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"JI7kFp6PjxnJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734012229805,"user_tz":-330,"elapsed":34586,"user":{"displayName":"SAURABH KUMAR","userId":"00862168303085254370"}},"outputId":"1fa55e8c-9e95-4620-ba65-bd8875b131d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"SroLlViB3uVq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734012234540,"user_tz":-330,"elapsed":583,"user":{"displayName":"SAURABH KUMAR","userId":"00862168303085254370"}},"outputId":"074e0652-42f4-42e5-8c3d-0b6a4e7432c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/PhD/transliteration\n"]}],"source":["%cd /content/drive/MyDrive/PhD/transliteration"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"2eSvM9zX_2d3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734012526186,"user_tz":-330,"elapsed":137563,"user":{"displayName":"SAURABH KUMAR","userId":"00862168303085254370"}},"outputId":"98ab7fae-db49-4dd6-c749-ab2db3e743bc"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Ignoring invalid distribution -vidia-cudnn-cu12 (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0mCollecting unsloth\n","  Using cached unsloth-2024.12.4-py3-none-any.whl.metadata (59 kB)\n","Collecting xformers==0.0.28.post2\n","  Using cached xformers-0.0.28.post2-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers==0.0.28.post2) (1.26.4)\n","Collecting torch==2.5.0 (from xformers==0.0.28.post2)\n","  Using cached torch-2.5.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->xformers==0.0.28.post2) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->xformers==0.0.28.post2) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->xformers==0.0.28.post2) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->xformers==0.0.28.post2) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->xformers==0.0.28.post2) (2024.9.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->xformers==0.0.28.post2) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->xformers==0.0.28.post2) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->xformers==0.0.28.post2) (12.4.127)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.0->xformers==0.0.28.post2)\n","  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->xformers==0.0.28.post2) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->xformers==0.0.28.post2) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->xformers==0.0.28.post2) (10.3.5.147)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.0->xformers==0.0.28.post2)\n","  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->xformers==0.0.28.post2) (12.3.1.170)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->xformers==0.0.28.post2) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->xformers==0.0.28.post2) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->xformers==0.0.28.post2) (12.4.127)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->xformers==0.0.28.post2) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->xformers==0.0.28.post2) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.0->xformers==0.0.28.post2) (1.3.0)\n","Collecting unsloth_zoo>=2024.11.8 (from unsloth)\n","  Using cached unsloth_zoo-2024.12.1-py3-none-any.whl.metadata (16 kB)\n","Collecting bitsandbytes (from unsloth)\n","  Using cached bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl.metadata (2.9 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth) (24.2)\n","Collecting tyro (from unsloth)\n","  Using cached tyro-0.9.2-py3-none-any.whl.metadata (9.4 kB)\n","Requirement already satisfied: transformers>=4.46.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (4.46.3)\n","Collecting datasets>=2.16.0 (from unsloth)\n","  Using cached datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.2.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth) (4.66.6)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth) (5.9.5)\n","Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.45.1)\n","Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (1.1.1)\n","Collecting trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 (from unsloth)\n","  Using cached trl-0.12.2-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.13.2)\n","Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (3.20.3)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.26.3)\n","Requirement already satisfied: hf_transfer in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.1.8)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (0.4.5)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (2.32.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.5.0)\n","Collecting multiprocess<0.70.17 (from datasets>=2.16.0->unsloth)\n","  Using cached multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.11.9)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.1->unsloth) (2024.9.11)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.1->unsloth) (0.20.3)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (13.9.4)\n","Collecting cut_cross_entropy (from unsloth_zoo>=2024.11.8->unsloth)\n","  Using cached cut_cross_entropy-24.12.2-py3-none-any.whl.metadata (9.3 kB)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2024.11.8->unsloth) (11.0.0)\n","Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (0.16)\n","Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (1.7.1)\n","Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (4.4.1)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.3.1)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (4.0.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.18.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2024.8.30)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (2.18.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.0->xformers==0.0.28.post2) (3.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2024.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth) (1.16.0)\n","Using cached xformers-0.0.28.post2-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n","Using cached torch-2.5.0-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n","Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","Using cached unsloth-2024.12.4-py3-none-any.whl (174 kB)\n","Using cached datasets-3.2.0-py3-none-any.whl (480 kB)\n","Using cached trl-0.12.2-py3-none-any.whl (365 kB)\n","Using cached unsloth_zoo-2024.12.1-py3-none-any.whl (60 kB)\n","Using cached bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\n","Using cached tyro-0.9.2-py3-none-any.whl (112 kB)\n","Using cached multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","Using cached cut_cross_entropy-24.12.2-py3-none-any.whl (22 kB)\n","\u001b[33mWARNING: Ignoring invalid distribution -vidia-cudnn-cu12 (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0mInstalling collected packages: nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, tyro, torch, xformers, cut_cross_entropy, bitsandbytes, datasets, trl, unsloth_zoo, unsloth\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n","    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.5.1+cu121\n","    Uninstalling torch-2.5.1+cu121:\n","      Successfully uninstalled torch-2.5.1+cu121\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.5.0 which is incompatible.\n","torchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 2.5.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed bitsandbytes-0.45.0 cut_cross_entropy-24.12.2 datasets-3.2.0 multiprocess-0.70.16 nvidia-cudnn-cu12-9.1.0.70 nvidia-cusolver-cu12-11.6.1.9 torch-2.5.0 trl-0.12.2 tyro-0.9.2 unsloth-2024.12.4 unsloth_zoo-2024.12.1 xformers-0.0.28.post2\n","Found existing installation: unsloth 2024.12.4\n","Uninstalling unsloth-2024.12.4:\n","  Successfully uninstalled unsloth-2024.12.4\n","\u001b[33mWARNING: Ignoring invalid distribution -vidia-cudnn-cu12 (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0mCollecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n","  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-x2sadz5s/unsloth_7a01d657cbec456ca60cff58eed7fd52\n","  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-x2sadz5s/unsloth_7a01d657cbec456ca60cff58eed7fd52\n","  Resolved https://github.com/unslothai/unsloth.git to commit 85f1fa096afde5efe2fb8521d8ceec8d13a00715\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: unsloth_zoo>=2024.11.8 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.12.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.2)\n","Requirement already satisfied: tyro in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.9.2)\n","Requirement already satisfied: transformers>=4.46.1 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.46.3)\n","Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.2.0)\n","Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.66.6)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.5)\n","Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.45.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.26.4)\n","Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.26.3)\n","Requirement already satisfied: hf_transfer in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.8)\n","Requirement already satisfied: bitsandbytes>=0.43.3 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.45.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.5.0)\n","Requirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.12.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.16.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.9.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.11.9)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.9.11)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.20.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.5)\n","Requirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2024.11.8->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.0)\n","Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2024.11.8->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.1.1)\n","Requirement already satisfied: trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2024.11.8->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.12.2)\n","Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2024.11.8->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.13.2)\n","Requirement already satisfied: cut_cross_entropy in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2024.11.8->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.12.2)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2024.11.8->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.0.0)\n","Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n","Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.9.4)\n","Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.7.1)\n","Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.4.1)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.1)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.0.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.18.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.8.30)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.18.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.4)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.3.1.170)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.2)\n","Building wheels for collected packages: unsloth\n","  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for unsloth: filename=unsloth-2024.12.4-py3-none-any.whl size=173746 sha256=182413d07a8a42cc491313163bf97c27db8642f180f400a658c42ca3c23e6af3\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-nhepqnr4/wheels/ed/d4/e9/76fb290ee3df0a5fc21ce5c2c788e29e9607a2353d8342fd0d\n","Successfully built unsloth\n","\u001b[33mWARNING: Ignoring invalid distribution -vidia-cudnn-cu12 (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0mInstalling collected packages: unsloth\n","Successfully installed unsloth-2024.12.4\n"]}],"source":["# %%capture\n","!pip install unsloth \"xformers==0.0.28.post2\"\n","# Also get the latest nightly Unsloth!\n","!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\""]},{"cell_type":"markdown","metadata":{"id":"r2v_X2fA0Df5"},"source":["* We support Llama, Mistral, Phi-3, Gemma, Yi, DeepSeek, Qwen, TinyLlama, Vicuna, Open Hermes etc\n","* We support 16bit LoRA or 4bit QLoRA. Both 2x faster.\n","* `max_seq_length` can be set to anything, since we do automatic RoPE Scaling via [kaiokendev's](https://kaiokendev.github.io/til) method.\n","* [**NEW**] We make Gemma-2 9b / 27b **2x faster**! See our [Gemma-2 9b notebook](https://colab.research.google.com/drive/1vIrqH5uYDQwsJ4-OO3DErvuv4pBgVwk4?usp=sharing)\n","* [**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/drive/1WZDi7APtQ9VsvOrQSSC5DDtxq159j8iZ?usp=sharing)\n","* [**NEW**] We make Mistral NeMo 12B 2x faster and fit in under 12GB of VRAM! [Mistral NeMo notebook](https://colab.research.google.com/drive/17d3U-CAIwzmbDRqbZ9NnpHxCkmXB6LZ0?usp=sharing)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QmUBVEnvCDJv","outputId":"9efc22b1-346a-4e4d-dc9e-6428bc9b755d","executionInfo":{"status":"ok","timestamp":1734012587717,"user_tz":-330,"elapsed":41474,"user":{"displayName":"SAURABH KUMAR","userId":"00862168303085254370"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","ü¶• Unsloth Zoo will now patch everything to make training faster!\n"]}],"source":["from unsloth import FastLanguageModel\n","import torch\n","max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n","dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n","load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n","\n","# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n","fourbit_models = [\n","    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 15 trillion tokens model 2x faster!\n","    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n","    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n","    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # We also uploaded 4bit for 405b!\n","    \"unsloth/Mistral-Nemo-Base-2407-bnb-4bit\", # New Mistral 12b 2x faster!\n","    \"unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit\",\n","    \"unsloth/mistral-7b-v0.3-bnb-4bit\",        # Mistral v3 2x faster!\n","    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n","    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n","    \"unsloth/Phi-3-medium-4k-instruct\",\n","    \"unsloth/gemma-2-9b-bnb-4bit\",\n","    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n","] # More models at https://huggingface.co/unsloth"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"cq8kcYoXSoBy","outputId":"e3e0d569-518a-415e-cb5c-fdd3b3634dcd","colab":{"base_uri":"https://localhost:8080/","height":286,"referenced_widgets":["e7ad380cd80845bd97efa6ce8adbf7e9","66f2c022d26e49b489a080f4c9b8849a","a040976a7fb243ea8f9a7ea57dbaf28b","92843d4d67864abba8e69df70ccd435a","4aad541f4be64e8d86337c465bbc3f37","794c58239a3840d09fa9d3abc4b758a4","e659857fb747459ea1e57fd293ce3399","0b169231aa7c4e839bf802f785cb68a7","f0cdfe30edd24e09aaded318df942e7d","f64974600f8045a78ac572819c99a180","fce9b1c24431492e9a1e3f0df1d4261d","9460111224c148ed913ab0a1a2eeb33e","754f2867bbd34e46bac5b09e20d65004","86328dd42dc44013bc9b46c96b8cb2ee","693b2914c8f1490e984483508815cd0b","df165d2f4348491cab0d385655f58436","63436429b1314f43b7c4cb5ebbb441a6","ce05a61a08e04cc19c5f673f93382710","70adfeb53324459d8c84faf9542a6920","94de4c54110b46e389f5136b906cfa09","104808acd408449baa739ff95ec8eea0","5f7c515eaaa64f058f04e2439760f17b","63c1f2db2dc94722b845066fd637fb7d","6a34ddb2b813475381422c16eaae1e48","0f5f81eaccb44311b8bf7bb27821dd24","0df778f0a0424995922ace22aabe1b68","73e0ed37c3dd435eaa9864365afac39f","f87070fddefc48d5b327222f0e0449a3","8e340215b64147ff933d2124aef58f9b","0246ab31719e47128de0f970179020f1","eae9a59ed9b14c13a23fb24446ab89f0","682481d1dbe54a83a52a9d1c59288bad","942f03f96bd24730ac45f2ebb3c3e964","7fffec88913c405eb2c531d59189d8f7","b89727b58953408187dbc26d552aaf99","de4d247318fe4fb08751273e493ceec6","77c79fe776724c4d9853af6dd8970e7b","aaae0c3ad6054c0da20a8d03afce7392","b47882055f7a4a209677478a9b1248ca","60700948db91428698966a6f4f415bd2","87b044e3c1f149529c4a563189ad7be6","b583a5728b80418f8d6bbfd6eaec78df","8075f20200464b9e87c4ef074206b767","2374b14960e04d80863e86f349121bef","e33374ed18764b19a4fc7bcc475511b4","71acb52d93f04cff98e95fccc9e7fffb","76fd39f2cb2141b9b61cea271d135a97","9614ec27789643db9d615aa098eea45f","9bfe0a6907a84180af220401f1001f3e","7ad42b6e1f6a47d88255a3f54f27c52b","011ce8e03b6a4c6ead4704377c54e311","3a1a3374bc4948c489a201edcf39986a","388318549c9049e696fe75d81ff43aff","db698a7dc315478990486d9a2906e165","d78121dbfc1243fea605fe79e9b6a829"]},"executionInfo":{"status":"ok","timestamp":1734012707836,"user_tz":-330,"elapsed":114762,"user":{"displayName":"SAURABH KUMAR","userId":"00862168303085254370"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth 2024.12.4: Fast Llama patching. Transformers:4.46.3.\n","   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.5.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.1.0\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post2. FA2 = False]\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7ad380cd80845bd97efa6ce8adbf7e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/230 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9460111224c148ed913ab0a1a2eeb33e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63c1f2db2dc94722b845066fd637fb7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fffec88913c405eb2c531d59189d8f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/345 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e33374ed18764b19a4fc7bcc475511b4"}},"metadata":{}}],"source":["model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"unsloth/Meta-Llama-3.1-8B\",\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit,\n","    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",")"]},{"cell_type":"markdown","metadata":{"id":"SXd9bTZd1aaL"},"source":["We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6bZsfBuZDeCL","outputId":"3a536daf-efec-494b-fce1-ae26a38ca1be","executionInfo":{"status":"ok","timestamp":1734012714705,"user_tz":-330,"elapsed":6870,"user":{"displayName":"SAURABH KUMAR","userId":"00862168303085254370"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Unsloth 2024.12.4 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"]}],"source":["model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n","    lora_alpha = 16,\n","    lora_dropout = 0, # Supports any, but = 0 is optimized\n","    bias = \"none\",    # Supports any, but = \"none\" is optimized\n","    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n","    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n","    random_state = 3407,\n","    use_rslora = False,  # We support rank stabilized LoRA\n","    loftq_config = None, # And LoftQ\n",")"]},{"cell_type":"markdown","metadata":{"id":"vITh0KVJ10qX"},"source":["<a name=\"Data\"></a>\n","### Data Prep\n","We now use the Alpaca dataset from [yahma](https://huggingface.co/datasets/yahma/alpaca-cleaned), which is a filtered version of 52K of the original [Alpaca dataset](https://crfm.stanford.edu/2023/03/13/alpaca.html). You can replace this code section with your own data prep.\n","\n","**[NOTE]** To train only on completions (ignoring the user's input) read TRL's docs [here](https://huggingface.co/docs/trl/sft_trainer#train-on-completions-only).\n","\n","**[NOTE]** Remember to add the **EOS_TOKEN** to the tokenized output!! Otherwise you'll get infinite generations!\n","\n","If you want to use the `llama-3` template for ShareGPT datasets, try our conversational [notebook](https://colab.research.google.com/drive/1XamvWYinY6FOSX9GLvnqSjjsNflxdhNc?usp=sharing).\n","\n","For text completions like novel writing, try this [notebook](https://colab.research.google.com/drive/1ef-tab5bhkvWmBOObepl1WgJvfvSzn5Q?usp=sharing)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LjY75GoYUCB8"},"outputs":[],"source":["alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","{}\n","\n","### Input:\n","{}\n","\n","### Response:\n","{}\"\"\"\n","\n","import pandas as pd\n","from datasets import Dataset\n","\n","# Define EOS token (end-of-sequence token)\n","EOS_TOKEN = tokenizer.eos_token  # Make sure EOS_TOKEN is set\n","\n","# Formatting function for prompts\n","def formatting_prompts_func(examples):\n","    instructions = examples[\"instruction\"]\n","    # instructions = \"Transliterate the given Romanized Hindi text back to Devanagari script.\"\n","    inputs = examples[\"input\"]\n","    outputs = examples[\"output\"]\n","    texts = []\n","    for instruction, input, output in zip(instructions, inputs, outputs):\n","        # Add EOS_TOKEN to prevent endless generation\n","        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n","        texts.append(text)\n","    return {\"text\": texts}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IGbSgYD9fo1b"},"outputs":[],"source":["# Load local CSV file\n","csv_file = \"/content/drive/MyDrive/PhD/transliteration/data/hi_roman_native_google.csv\"\n","df = pd.read_csv(csv_file,encoding='utf-8',usecols=range(2),header=None, names=['input','output'])\n","df[\"instruction\"] = \"Transliterate the given Romanized Hindi text back to Devanagari script.\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"JzQoci2a7R5l","outputId":"d03d3cb7-37e7-4ffc-eb82-e9a2dcfd97f2"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>input</th>\n","      <th>output</th>\n","      <th>instruction</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Jabki yah Jainon se km hai.</td>\n","      <td>‡§ú‡§¨‡§ï‡§ø ‡§Ø‡§π ‡§ú‡•à‡§®‡•ã‡§Ç ‡§∏‡•á ‡§ï‡§Æ ‡§π‡•à‡•§</td>\n","      <td>Transliterate the given Romanized Hindi text b...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Varsh 2000 men Venkatraman ne prayogshala men ...</td>\n","      <td>‡§µ‡§∞‡•ç‡§∑ 2000 ‡§Æ‡•á‡§Ç ‡§µ‡•á‡§Ç‡§ï‡§ü‡§∞‡§æ‡§Æ‡§® ‡§®‡•á ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡§∂‡§æ‡§≤‡§æ ‡§Æ‡•á‡§Ç ‡§∞‡§æ‡§á‡§¨...</td>\n","      <td>Transliterate the given Romanized Hindi text b...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Is vriksha ki lambai takriban 50 se 60 feet ke...</td>\n","      <td>‡§á‡§∏ ‡§µ‡•É‡§ï‡•ç‡§∑ ‡§ï‡•Ä ‡§≤‡§Ç‡§¨‡§æ‡§à ‡§§‡§ï‡§∞‡•Ä‡§¨‡§® ‡•´‡•¶ ‡§∏‡•á ‡•¨‡•¶ ‡§´‡•Ä‡§ü ‡§ï‡•á ‡§Ü‡§∏‡§™‡§æ‡§∏...</td>\n","      <td>Transliterate the given Romanized Hindi text b...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>In anusandhan karyakramon men tara rachana, ta...</td>\n","      <td>‡§á‡§® ‡§Ö‡§®‡•Å‡§∏‡§Ç‡§ß‡§æ‡§® ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡•ç‡§∞‡§Æ‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§§‡§æ‡§∞‡§æ ‡§∞‡§ö‡§®‡§æ, ‡§§‡§æ‡§∞‡§ï‡•Ä‡§Ø ...</td>\n","      <td>Transliterate the given Romanized Hindi text b...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1 November 1919 ko magistrate B. S. Kris ne Ma...</td>\n","      <td>‡•ß ‡§®‡§¨‡§Æ‡•ç‡§¨‡§∞ ‡•ß‡•Ø‡•ß‡•Ø ‡§ï‡•ã ‡§Æ‡§ú‡§ø‡§∏‡•ç‡§ü‡•ç‡§∞‡•á‡§ü ‡§¨‡•Ä‡•∞ ‡§è‡§∏‡•∞ ‡§ï‡•ç‡§∞‡§ø‡§∏ ‡§®‡•á ‡§Æ...</td>\n","      <td>Transliterate the given Romanized Hindi text b...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               input  \\\n","0                        Jabki yah Jainon se km hai.   \n","1  Varsh 2000 men Venkatraman ne prayogshala men ...   \n","2  Is vriksha ki lambai takriban 50 se 60 feet ke...   \n","3  In anusandhan karyakramon men tara rachana, ta...   \n","4  1 November 1919 ko magistrate B. S. Kris ne Ma...   \n","\n","                                              output  \\\n","0                            ‡§ú‡§¨‡§ï‡§ø ‡§Ø‡§π ‡§ú‡•à‡§®‡•ã‡§Ç ‡§∏‡•á ‡§ï‡§Æ ‡§π‡•à‡•§   \n","1  ‡§µ‡§∞‡•ç‡§∑ 2000 ‡§Æ‡•á‡§Ç ‡§µ‡•á‡§Ç‡§ï‡§ü‡§∞‡§æ‡§Æ‡§® ‡§®‡•á ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡§∂‡§æ‡§≤‡§æ ‡§Æ‡•á‡§Ç ‡§∞‡§æ‡§á‡§¨...   \n","2  ‡§á‡§∏ ‡§µ‡•É‡§ï‡•ç‡§∑ ‡§ï‡•Ä ‡§≤‡§Ç‡§¨‡§æ‡§à ‡§§‡§ï‡§∞‡•Ä‡§¨‡§® ‡•´‡•¶ ‡§∏‡•á ‡•¨‡•¶ ‡§´‡•Ä‡§ü ‡§ï‡•á ‡§Ü‡§∏‡§™‡§æ‡§∏...   \n","3  ‡§á‡§® ‡§Ö‡§®‡•Å‡§∏‡§Ç‡§ß‡§æ‡§® ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§ï‡•ç‡§∞‡§Æ‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§§‡§æ‡§∞‡§æ ‡§∞‡§ö‡§®‡§æ, ‡§§‡§æ‡§∞‡§ï‡•Ä‡§Ø ...   \n","4  ‡•ß ‡§®‡§¨‡§Æ‡•ç‡§¨‡§∞ ‡•ß‡•Ø‡•ß‡•Ø ‡§ï‡•ã ‡§Æ‡§ú‡§ø‡§∏‡•ç‡§ü‡•ç‡§∞‡•á‡§ü ‡§¨‡•Ä‡•∞ ‡§è‡§∏‡•∞ ‡§ï‡•ç‡§∞‡§ø‡§∏ ‡§®‡•á ‡§Æ...   \n","\n","                                         instruction  \n","0  Transliterate the given Romanized Hindi text b...  \n","1  Transliterate the given Romanized Hindi text b...  \n","2  Transliterate the given Romanized Hindi text b...  \n","3  Transliterate the given Romanized Hindi text b...  \n","4  Transliterate the given Romanized Hindi text b...  "]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df.head(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o9-nPHz_f21U"},"outputs":[],"source":["# Convert DataFrame to a Hugging Face Dataset\n","dataset = Dataset.from_pandas(df)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c_oOvint7XlX","outputId":"fc9f5442-83d1-41dc-8621-591d37261096"},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['input', 'output', 'instruction'],\n","    num_rows: 9963\n","})"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A493PIdFcOY7","outputId":"5f99932c-398f-4589-f386-28178f9f2a4f"},"outputs":[{"data":{"text/plain":["{'input': 'Varsh 2000 men Venkatraman ne prayogshala men Ribosome ki tees ikaiyon ka pata lagaya aur pratijaivikon ke saath unke yougikon par bhi anusandhan kiya.',\n"," 'output': '‡§µ‡§∞‡•ç‡§∑ 2000 ‡§Æ‡•á‡§Ç ‡§µ‡•á‡§Ç‡§ï‡§ü‡§∞‡§æ‡§Æ‡§® ‡§®‡•á ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡§∂‡§æ‡§≤‡§æ ‡§Æ‡•á‡§Ç ‡§∞‡§æ‡§á‡§¨‡•ã‡§∏‡•ã‡§Æ ‡§ï‡•Ä ‡§§‡•Ä‡§∏ ‡§à‡§ï‡§æ‡§à‡§Ø‡•ã‡§Ç ‡§ï‡§æ ‡§™‡§§‡§æ ‡§≤‡§ó‡§æ‡§Ø‡§æ ‡§î‡§∞ ‡§™‡•ç‡§∞‡§§‡§ø‡§ú‡•à‡§µ‡§ø‡§ï‡•ã‡§Ç ‡§ï‡•á ‡§∏‡§æ‡§• ‡§á‡§®‡§ï‡•á ‡§Ø‡•å‡§ó‡§ø‡§ï‡•ã‡§Ç ‡§™‡§∞ ‡§≠‡•Ä ‡§Ö‡§®‡•Å‡§∏‡§Ç‡§ß‡§æ‡§® ‡§ï‡§ø‡§Ø‡§æ‡•§',\n"," 'instruction': 'Transliterate the given Romanized Hindi text back to Devanagari script.'}"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["dataset[1]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["287257bc9dc0489285a0d34d373e663e","e0049bb0e6fb4bc89a1cc9cd0fd0999e","bccb6826499f4fdeaf9c967706630634","e51e503d7e004e3b92a5d2039644c5f2","d4572670f3c34628b6660f2145145804","16bc9731b5424651b80e5bb1fdb8a85a","f6f5001e6e524376bce25a8951587244","0cc7493ad2c0494494e8101386808141","afee8c5ec0fa4e4d9faf5928122469c8","a85d31f3d63b4912af5096f31edf585d","5383261d8bf8433abf7a5ca4012cf107"]},"id":"bWn6C4yBcK37","outputId":"21333450-a6c5-49a7-e811-4a4067bbfc78"},"outputs":[{"name":"stderr","output_type":"stream","text":["Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9963/9963 [00:00<00:00, 109090.99 examples/s]\n"]}],"source":["# Map formatting function to the dataset\n","dataset = dataset.map(formatting_prompts_func, batched=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LS9xifT0bkJi","outputId":"3b662cb1-16df-49ef-dbc4-44f66535ab31"},"outputs":[{"data":{"text/plain":["{'input': 'Jabki yah Jainon se km hai.',\n"," 'output': '‡§ú‡§¨‡§ï‡§ø ‡§Ø‡§π ‡§ú‡•à‡§®‡•ã‡§Ç ‡§∏‡•á ‡§ï‡§Æ ‡§π‡•à‡•§',\n"," 'instruction': 'Transliterate the given Romanized Hindi text back to Devanagari script.',\n"," 'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nTransliterate the given Romanized Hindi text back to Devanagari script.\\n\\n### Input:\\nJabki yah Jainon se km hai.\\n\\n### Response:\\n‡§ú‡§¨‡§ï‡§ø ‡§Ø‡§π ‡§ú‡•à‡§®‡•ã‡§Ç ‡§∏‡•á ‡§ï‡§Æ ‡§π‡•à‡•§<|end_of_text|>'}"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["dataset[0]"]},{"cell_type":"markdown","metadata":{"id":"idAEIeSQ3xdS"},"source":["<a name=\"Train\"></a>\n","### Train the model\n","Now let's use Huggingface TRL's `SFTTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"95_Nn-89DhsL","outputId":"ad490efc-24bf-4979-8c3a-d078ed4d3968"},"outputs":[{"name":"stderr","output_type":"stream","text":["Generating train split: 693 examples [00:00, 779.49 examples/s]\n"]}],"source":["from trl import SFTTrainer\n","from transformers import TrainingArguments\n","from unsloth import is_bfloat16_supported\n","\n","trainer = SFTTrainer(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset = dataset,\n","    dataset_text_field = \"text\",\n","    max_seq_length = max_seq_length,\n","    dataset_num_proc = 2,\n","    packing = True, # Can make training 5x faster for short sequences.\n","    args = TrainingArguments(\n","        per_device_train_batch_size = 2,\n","        gradient_accumulation_steps = 4,\n","        warmup_steps = 5,\n","        num_train_epochs = 1, # Set this for 1 full training run.\n","        # max_steps = None,\n","        learning_rate = 2e-4,\n","        fp16 = not is_bfloat16_supported(),\n","        bf16 = is_bfloat16_supported(),\n","        logging_steps = 1,\n","        optim = \"adamw_8bit\",\n","        weight_decay = 0.01,\n","        lr_scheduler_type = \"linear\",\n","        seed = 3407,\n","        output_dir = \"outputs\",\n","        report_to = \"none\", # Use this for WandB etc\n","    ),\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"yqxqAZ7KJ4oL","outputId":"13ae7cc0-3f14-4941-f4a6-b6b4e04bc4f2"},"outputs":[{"name":"stderr","output_type":"stream","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n","   \\\\   /|    Num examples = 693 | Num Epochs = 1\n","O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n","\\        /    Total batch size = 8 | Total steps = 86\n"," \"-____-\"     Number of trainable parameters = 41,943,040\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='86' max='86' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [86/86 26:29, Epoch 0/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.600600</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.667700</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>1.652900</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>1.578500</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>1.413700</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>1.377100</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>1.317500</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>1.280700</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>1.276600</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>1.270900</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>1.296400</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>1.287700</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>1.171600</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>1.150300</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>1.167000</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>1.117300</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>1.116400</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>1.113700</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>1.113300</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>1.044500</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>1.050700</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>1.055800</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>1.071400</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>1.047100</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>1.000800</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>1.091000</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>1.043100</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>1.032500</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>1.057900</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>1.030600</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>1.007800</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>1.018800</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>1.006900</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>1.028000</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>1.032300</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>1.056300</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>1.019100</td>\n","    </tr>\n","    <tr>\n","      <td>38</td>\n","      <td>1.098300</td>\n","    </tr>\n","    <tr>\n","      <td>39</td>\n","      <td>1.002600</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>1.032900</td>\n","    </tr>\n","    <tr>\n","      <td>41</td>\n","      <td>1.060700</td>\n","    </tr>\n","    <tr>\n","      <td>42</td>\n","      <td>1.024400</td>\n","    </tr>\n","    <tr>\n","      <td>43</td>\n","      <td>1.006900</td>\n","    </tr>\n","    <tr>\n","      <td>44</td>\n","      <td>0.987700</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>0.992100</td>\n","    </tr>\n","    <tr>\n","      <td>46</td>\n","      <td>1.081100</td>\n","    </tr>\n","    <tr>\n","      <td>47</td>\n","      <td>0.956100</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>0.946700</td>\n","    </tr>\n","    <tr>\n","      <td>49</td>\n","      <td>1.049700</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.974400</td>\n","    </tr>\n","    <tr>\n","      <td>51</td>\n","      <td>1.048800</td>\n","    </tr>\n","    <tr>\n","      <td>52</td>\n","      <td>0.947000</td>\n","    </tr>\n","    <tr>\n","      <td>53</td>\n","      <td>1.003000</td>\n","    </tr>\n","    <tr>\n","      <td>54</td>\n","      <td>0.976700</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>0.988200</td>\n","    </tr>\n","    <tr>\n","      <td>56</td>\n","      <td>1.017300</td>\n","    </tr>\n","    <tr>\n","      <td>57</td>\n","      <td>1.024600</td>\n","    </tr>\n","    <tr>\n","      <td>58</td>\n","      <td>0.963500</td>\n","    </tr>\n","    <tr>\n","      <td>59</td>\n","      <td>0.989600</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.955100</td>\n","    </tr>\n","    <tr>\n","      <td>61</td>\n","      <td>0.960400</td>\n","    </tr>\n","    <tr>\n","      <td>62</td>\n","      <td>0.962000</td>\n","    </tr>\n","    <tr>\n","      <td>63</td>\n","      <td>0.938000</td>\n","    </tr>\n","    <tr>\n","      <td>64</td>\n","      <td>1.001600</td>\n","    </tr>\n","    <tr>\n","      <td>65</td>\n","      <td>0.959300</td>\n","    </tr>\n","    <tr>\n","      <td>66</td>\n","      <td>0.981100</td>\n","    </tr>\n","    <tr>\n","      <td>67</td>\n","      <td>0.918500</td>\n","    </tr>\n","    <tr>\n","      <td>68</td>\n","      <td>1.025400</td>\n","    </tr>\n","    <tr>\n","      <td>69</td>\n","      <td>0.981400</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.982200</td>\n","    </tr>\n","    <tr>\n","      <td>71</td>\n","      <td>0.998200</td>\n","    </tr>\n","    <tr>\n","      <td>72</td>\n","      <td>0.988500</td>\n","    </tr>\n","    <tr>\n","      <td>73</td>\n","      <td>1.003900</td>\n","    </tr>\n","    <tr>\n","      <td>74</td>\n","      <td>0.994300</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.986400</td>\n","    </tr>\n","    <tr>\n","      <td>76</td>\n","      <td>0.963300</td>\n","    </tr>\n","    <tr>\n","      <td>77</td>\n","      <td>0.933100</td>\n","    </tr>\n","    <tr>\n","      <td>78</td>\n","      <td>0.951000</td>\n","    </tr>\n","    <tr>\n","      <td>79</td>\n","      <td>1.031600</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>1.016500</td>\n","    </tr>\n","    <tr>\n","      <td>81</td>\n","      <td>0.977800</td>\n","    </tr>\n","    <tr>\n","      <td>82</td>\n","      <td>1.053600</td>\n","    </tr>\n","    <tr>\n","      <td>83</td>\n","      <td>0.956900</td>\n","    </tr>\n","    <tr>\n","      <td>84</td>\n","      <td>0.956700</td>\n","    </tr>\n","    <tr>\n","      <td>85</td>\n","      <td>1.009800</td>\n","    </tr>\n","    <tr>\n","      <td>86</td>\n","      <td>0.963900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["trainer_stats = trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"ekOmTR1hSNcr"},"source":["<a name=\"Inference\"></a>\n","### Inference\n","Let's run the model! You can change the instruction and input - leave the output blank!\n","\n","**[NEW] Try 2x faster inference in a free Colab for Llama-3.1 8b Instruct [here](https://colab.research.google.com/drive/1T-YBVfnphoVc8E2E854qF3jdia2Ll2W2?usp=sharing)**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kR3gIAX-SM2q","outputId":"087c5c13-e946-4c35-e4f2-e07a88f9ac32"},"outputs":[{"data":{"text/plain":["'1 3/16 ‡§á‡§Ç‡§ö (30 ‡§Æ‡§ø‡§Æ‡•Ä) ‡§ï‡•á ‡§ï‡§ø‡§®‡§æ‡§∞‡•á ‡§ï‡•á ‡§µ‡§∞‡•ç‡§ó ‡§ï‡•Ä ‡§¨‡§æ‡§π‡§∞‡•Ä ‡§∞‡•á‡§ñ‡§æ‡§ì‡§Ç ‡§∏‡•á ‡§¨‡§®‡§æ ‡§ï‡•á‡§Ç‡§¶‡•ç‡§∞ ‡§ï‡•á'"]},"execution_count":384,"metadata":{},"output_type":"execute_result"}],"source":["# alpaca_prompt = Copied from above\n","alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","{}\n","\n","### Input:\n","{}\n","\n","### Response:\n","{}\"\"\"\n","FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","inputs = tokenizer(\n","[\n","    alpaca_prompt.format(\n","        \"Transliterate the given Romanized Hindi text back to Devanagari script.\", # instruction\n","        '1 3/16 inch (30 mm) ke kinare ke varg ki bahari rekhaon se bana kendra ke', # input\n","        \"\", # output - leave this blank for generation!\n","    )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","outputs = model.generate(**inputs, max_new_tokens = 128, use_cache = True)\n","text=tokenizer.batch_decode(outputs,skip_special_tokens=True)[0]\n","text.split('\\n')[-1]"]},{"cell_type":"code","source":[],"metadata":{"id":"fTmaOXiCLa6Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6ziTaegKSoB1"},"outputs":[],"source":["import pandas as pd\n","test_file = \"Hindi_Test_Set_1.csv\"  # Replace with the path to your CSV\n","df_test = pd.read_csv(test_file,encoding='utf-8',usecols=range(2))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nUy8Z-ZGSoB2","outputId":"d65613e1-4fea-4b9d-9519-1df6c80fe414"},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing rows: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9998/9998 [6:06:25<00:00,  2.20s/row]\n"]}],"source":["import pandas as pd\n","from tqdm import tqdm\n","import csv\n","\n","# Open the output CSV file in append mode and write the header once\n","with open('Hindi_Test_Set_1_output_llama.csv', mode='w', newline='', encoding='utf-8') as file:\n","    writer = csv.writer(file)\n","\n","    # Write the header to the CSV (if it's the first time writing)\n","    writer.writerow(['roman', 'native','llama_output'])  # Adjust column names as needed\n","\n","    # Loop through each row in the CSV file, process, and generate output\n","    for index, row in tqdm(df_test.iterrows(), total=df_test.shape[0], desc=\"Processing rows\", unit=\"row\"):\n","        romanized_text = row['roman']# Assuming 'roman' is the correct column name\n","        native_text = row['native']\n","\n","        # Prepare the input in the required format\n","        alpaca_prompt = \"\"\"\n","        Transliterate the given Romanized Hindi text back to Devanagari script.\n","\n","        Input: {}\n","        Output:\n","        \"\"\"\n","\n","        formatted_input = alpaca_prompt.format(romanized_text)\n","\n","        # Tokenize the input and move it to GPU\n","        inputs = tokenizer([formatted_input], return_tensors=\"pt\").to(\"cuda\")\n","\n","        # Handle line length for max_new_tokens\n","        try:\n","            line_length = len(romanized_text)  # Get the length of the line\n","            max_new_tokens = line_length + 5  # Add a small margin\n","        except TypeError:  # Handle the case where romanized_text is None or invalid\n","            max_new_tokens = 64  # Default to 64 if an error occurs\n","\n","        # Generate the output from the model\n","        outputs = model.generate(**inputs, max_new_tokens=max_new_tokens, use_cache=True)\n","\n","        # Decode and extract the generated output\n","        decoded_output = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n","        decoded_output = (decoded_output.split('Output:')[1]).strip()\n","        # break\n","\n","        # Write the input and the transliterated output line by line\n","        writer.writerow([romanized_text,native_text, decoded_output])\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1E3dmryySoB2","outputId":"df80d076-4c6f-4a42-9c76-7e482f3f8d8b"},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing rows: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4998/4998 [2:47:24<00:00,  2.01s/row]\n"]}],"source":["import pandas as pd\n","test_file = \"Hindi_Test_Set_2.csv\"  # Replace with the path to your CSV\n","df_test = pd.read_csv(test_file,encoding='utf-8',usecols=range(2))\n","\n","# Open the output CSV file in append mode and write the header once\n","with open('Hindi_Test_Set_2_output_llama.csv', mode='w', newline='', encoding='utf-8') as file:\n","    writer = csv.writer(file)\n","\n","    # Write the header to the CSV (if it's the first time writing)\n","    writer.writerow(['roman', 'native','llama_output'])  # Adjust column names as needed\n","\n","    # Loop through each row in the CSV file, process, and generate output\n","    for index, row in tqdm(df_test.iterrows(), total=df_test.shape[0], desc=\"Processing rows\", unit=\"row\"):\n","        romanized_text = row['roman']# Assuming 'roman' is the correct column name\n","        native_text = row['native']\n","\n","        # Prepare the input in the required format\n","        alpaca_prompt = \"\"\"\n","        Transliterate the given Romanized Hindi text back to Devanagari script.\n","\n","        Input: {}\n","        Output:\n","        \"\"\"\n","\n","        formatted_input = alpaca_prompt.format(romanized_text)\n","\n","        # Tokenize the input and move it to GPU\n","        inputs = tokenizer([formatted_input], return_tensors=\"pt\").to(\"cuda\")\n","\n","        # Handle line length for max_new_tokens\n","        try:\n","            line_length = len(romanized_text)  # Get the length of the line\n","            max_new_tokens = line_length + 5  # Add a small margin\n","        except TypeError:  # Handle the case where romanized_text is None or invalid\n","            max_new_tokens = 64  # Default to 64 if an error occurs\n","\n","        # Generate the output from the model\n","        outputs = model.generate(**inputs, max_new_tokens=max_new_tokens, use_cache=True)\n","\n","        # Decode and extract the generated output\n","        decoded_output = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n","        decoded_output = (decoded_output.split('Output:')[1]).strip()\n","        # break\n","\n","        # Write the input and the transliterated output line by line\n","        writer.writerow([romanized_text,native_text, decoded_output])"]},{"cell_type":"markdown","metadata":{"id":"uMuVrWbjAzhc"},"source":["<a name=\"Save\"></a>\n","### Saving, loading finetuned models\n","To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n","\n","**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"upcOlWe7A1vc","outputId":"cc9473b2-c7cc-4b34-b450-0ef687d1603c"},"outputs":[{"data":{"text/plain":["('lora_model/tokenizer_config.json',\n"," 'lora_model/special_tokens_map.json',\n"," 'lora_model/tokenizer.json')"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["model.save_pretrained(\"lora_model\") # Local saving\n","tokenizer.save_pretrained(\"lora_model\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.10"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0cc7493ad2c0494494e8101386808141":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16bc9731b5424651b80e5bb1fdb8a85a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"287257bc9dc0489285a0d34d373e663e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e0049bb0e6fb4bc89a1cc9cd0fd0999e","IPY_MODEL_bccb6826499f4fdeaf9c967706630634","IPY_MODEL_e51e503d7e004e3b92a5d2039644c5f2"],"layout":"IPY_MODEL_d4572670f3c34628b6660f2145145804"}},"5383261d8bf8433abf7a5ca4012cf107":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a85d31f3d63b4912af5096f31edf585d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afee8c5ec0fa4e4d9faf5928122469c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bccb6826499f4fdeaf9c967706630634":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0cc7493ad2c0494494e8101386808141","max":9963,"min":0,"orientation":"horizontal","style":"IPY_MODEL_afee8c5ec0fa4e4d9faf5928122469c8","value":9963}},"d4572670f3c34628b6660f2145145804":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0049bb0e6fb4bc89a1cc9cd0fd0999e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_16bc9731b5424651b80e5bb1fdb8a85a","placeholder":"‚Äã","style":"IPY_MODEL_f6f5001e6e524376bce25a8951587244","value":"Map:‚Äá100%"}},"e51e503d7e004e3b92a5d2039644c5f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a85d31f3d63b4912af5096f31edf585d","placeholder":"‚Äã","style":"IPY_MODEL_5383261d8bf8433abf7a5ca4012cf107","value":"‚Äá9963/9963‚Äá[00:00&lt;00:00,‚Äá70269.43‚Äáexamples/s]"}},"f6f5001e6e524376bce25a8951587244":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e7ad380cd80845bd97efa6ce8adbf7e9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_66f2c022d26e49b489a080f4c9b8849a","IPY_MODEL_a040976a7fb243ea8f9a7ea57dbaf28b","IPY_MODEL_92843d4d67864abba8e69df70ccd435a"],"layout":"IPY_MODEL_4aad541f4be64e8d86337c465bbc3f37"}},"66f2c022d26e49b489a080f4c9b8849a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_794c58239a3840d09fa9d3abc4b758a4","placeholder":"‚Äã","style":"IPY_MODEL_e659857fb747459ea1e57fd293ce3399","value":"model.safetensors:‚Äá100%"}},"a040976a7fb243ea8f9a7ea57dbaf28b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b169231aa7c4e839bf802f785cb68a7","max":5702746390,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f0cdfe30edd24e09aaded318df942e7d","value":5702745847}},"92843d4d67864abba8e69df70ccd435a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f64974600f8045a78ac572819c99a180","placeholder":"‚Äã","style":"IPY_MODEL_fce9b1c24431492e9a1e3f0df1d4261d","value":"‚Äá5.70G/5.70G‚Äá[00:53&lt;00:00,‚Äá447MB/s]"}},"4aad541f4be64e8d86337c465bbc3f37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"794c58239a3840d09fa9d3abc4b758a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e659857fb747459ea1e57fd293ce3399":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0b169231aa7c4e839bf802f785cb68a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0cdfe30edd24e09aaded318df942e7d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f64974600f8045a78ac572819c99a180":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fce9b1c24431492e9a1e3f0df1d4261d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9460111224c148ed913ab0a1a2eeb33e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_754f2867bbd34e46bac5b09e20d65004","IPY_MODEL_86328dd42dc44013bc9b46c96b8cb2ee","IPY_MODEL_693b2914c8f1490e984483508815cd0b"],"layout":"IPY_MODEL_df165d2f4348491cab0d385655f58436"}},"754f2867bbd34e46bac5b09e20d65004":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_63436429b1314f43b7c4cb5ebbb441a6","placeholder":"‚Äã","style":"IPY_MODEL_ce05a61a08e04cc19c5f673f93382710","value":"generation_config.json:‚Äá100%"}},"86328dd42dc44013bc9b46c96b8cb2ee":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_70adfeb53324459d8c84faf9542a6920","max":230,"min":0,"orientation":"horizontal","style":"IPY_MODEL_94de4c54110b46e389f5136b906cfa09","value":230}},"693b2914c8f1490e984483508815cd0b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_104808acd408449baa739ff95ec8eea0","placeholder":"‚Äã","style":"IPY_MODEL_5f7c515eaaa64f058f04e2439760f17b","value":"‚Äá230/230‚Äá[00:00&lt;00:00,‚Äá18.1kB/s]"}},"df165d2f4348491cab0d385655f58436":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63436429b1314f43b7c4cb5ebbb441a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce05a61a08e04cc19c5f673f93382710":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"70adfeb53324459d8c84faf9542a6920":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94de4c54110b46e389f5136b906cfa09":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"104808acd408449baa739ff95ec8eea0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f7c515eaaa64f058f04e2439760f17b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"63c1f2db2dc94722b845066fd637fb7d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6a34ddb2b813475381422c16eaae1e48","IPY_MODEL_0f5f81eaccb44311b8bf7bb27821dd24","IPY_MODEL_0df778f0a0424995922ace22aabe1b68"],"layout":"IPY_MODEL_73e0ed37c3dd435eaa9864365afac39f"}},"6a34ddb2b813475381422c16eaae1e48":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f87070fddefc48d5b327222f0e0449a3","placeholder":"‚Äã","style":"IPY_MODEL_8e340215b64147ff933d2124aef58f9b","value":"tokenizer_config.json:‚Äá100%"}},"0f5f81eaccb44311b8bf7bb27821dd24":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0246ab31719e47128de0f970179020f1","max":50570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eae9a59ed9b14c13a23fb24446ab89f0","value":50570}},"0df778f0a0424995922ace22aabe1b68":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_682481d1dbe54a83a52a9d1c59288bad","placeholder":"‚Äã","style":"IPY_MODEL_942f03f96bd24730ac45f2ebb3c3e964","value":"‚Äá50.6k/50.6k‚Äá[00:00&lt;00:00,‚Äá2.12MB/s]"}},"73e0ed37c3dd435eaa9864365afac39f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f87070fddefc48d5b327222f0e0449a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e340215b64147ff933d2124aef58f9b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0246ab31719e47128de0f970179020f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eae9a59ed9b14c13a23fb24446ab89f0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"682481d1dbe54a83a52a9d1c59288bad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"942f03f96bd24730ac45f2ebb3c3e964":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7fffec88913c405eb2c531d59189d8f7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b89727b58953408187dbc26d552aaf99","IPY_MODEL_de4d247318fe4fb08751273e493ceec6","IPY_MODEL_77c79fe776724c4d9853af6dd8970e7b"],"layout":"IPY_MODEL_aaae0c3ad6054c0da20a8d03afce7392"}},"b89727b58953408187dbc26d552aaf99":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b47882055f7a4a209677478a9b1248ca","placeholder":"‚Äã","style":"IPY_MODEL_60700948db91428698966a6f4f415bd2","value":"tokenizer.json:‚Äá100%"}},"de4d247318fe4fb08751273e493ceec6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_87b044e3c1f149529c4a563189ad7be6","max":9085657,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b583a5728b80418f8d6bbfd6eaec78df","value":9085657}},"77c79fe776724c4d9853af6dd8970e7b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8075f20200464b9e87c4ef074206b767","placeholder":"‚Äã","style":"IPY_MODEL_2374b14960e04d80863e86f349121bef","value":"‚Äá9.09M/9.09M‚Äá[00:00&lt;00:00,‚Äá13.4MB/s]"}},"aaae0c3ad6054c0da20a8d03afce7392":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b47882055f7a4a209677478a9b1248ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60700948db91428698966a6f4f415bd2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"87b044e3c1f149529c4a563189ad7be6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b583a5728b80418f8d6bbfd6eaec78df":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8075f20200464b9e87c4ef074206b767":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2374b14960e04d80863e86f349121bef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e33374ed18764b19a4fc7bcc475511b4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_71acb52d93f04cff98e95fccc9e7fffb","IPY_MODEL_76fd39f2cb2141b9b61cea271d135a97","IPY_MODEL_9614ec27789643db9d615aa098eea45f"],"layout":"IPY_MODEL_9bfe0a6907a84180af220401f1001f3e"}},"71acb52d93f04cff98e95fccc9e7fffb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ad42b6e1f6a47d88255a3f54f27c52b","placeholder":"‚Äã","style":"IPY_MODEL_011ce8e03b6a4c6ead4704377c54e311","value":"special_tokens_map.json:‚Äá100%"}},"76fd39f2cb2141b9b61cea271d135a97":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a1a3374bc4948c489a201edcf39986a","max":345,"min":0,"orientation":"horizontal","style":"IPY_MODEL_388318549c9049e696fe75d81ff43aff","value":345}},"9614ec27789643db9d615aa098eea45f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_db698a7dc315478990486d9a2906e165","placeholder":"‚Äã","style":"IPY_MODEL_d78121dbfc1243fea605fe79e9b6a829","value":"‚Äá345/345‚Äá[00:00&lt;00:00,‚Äá24.9kB/s]"}},"9bfe0a6907a84180af220401f1001f3e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ad42b6e1f6a47d88255a3f54f27c52b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"011ce8e03b6a4c6ead4704377c54e311":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3a1a3374bc4948c489a201edcf39986a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"388318549c9049e696fe75d81ff43aff":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"db698a7dc315478990486d9a2906e165":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d78121dbfc1243fea605fe79e9b6a829":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}